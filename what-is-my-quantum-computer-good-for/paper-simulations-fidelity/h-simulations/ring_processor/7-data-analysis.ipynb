{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 21:53:31.668876: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/anaconda3/envs/QPL/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "# a is the actual values while b is the predictions\n",
    "def bce(a, b):\n",
    "    return BinaryCrossentropy(from_logits = False)(a,b).numpy()\n",
    "\n",
    "dtypes = ['train', 'validate', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [0, 1, 2, 3, 4]\n",
    "exp_path = './experiment_{}/'\n",
    "pred_path = exp_path + 'predictions/'\n",
    "sps_path = exp_path + 'processed_inputs_and_outputs/'\n",
    "\n",
    "metric_functions = {'r': lambda x, y: np.corrcoef(x, y)[0,1],\n",
    "                    'kl': lambda x, y: bce(x, y) - bce(x, x),\n",
    "                    'l1': lambda x, y: np.mean(np.abs(x - y))\n",
    "                    }\n",
    "model_predictions = {'cnn': 'processed_cnn_predictions.npz', 'custom-nn': 'processed_custom_neural_net_predictions.npz',\n",
    "                    'mirrored-cnn': 'processed_cnn_mirrored_predictions.npz', 'mirrored-custom-nn': 'processed_custom_neural_net_mirrored_predictions.npz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing MAE performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(metric_function, model_types, circuits):\n",
    "    device_results = {}\n",
    "    for exp in experiments:\n",
    "        device_results[exp] = {}\n",
    "        if circuits != 'mirrored':\n",
    "            infidelities = np.load(sps_path.format(exp) + 'processed_infidelities.npz')\n",
    "        else:\n",
    "            infidelities = np.load(sps_path.format(exp) + 'processed_mirrored_infidelities.npz')\n",
    "        for model_type in model_types:\n",
    "            predictions = np.load(pred_path.format(exp)+model_predictions[model_type])\n",
    "            if model_type[0] != 'm':\n",
    "                predictions = {dt: predictions[dt].reshape((-1,)) for dt in dtypes}\n",
    "            else:\n",
    "                predictions = predictions['predictions'].reshape((-1,))\n",
    "            if model_type in ['custom-nn', 'cnn']:\n",
    "                device_results[exp][model_type] = metric_function(infidelities[circuits].reshape((-1,))/100, predictions[circuits].reshape((-1,))/100)\n",
    "            elif model_type in ['mirrored-custom-nn', 'mirrored-cnn']:\n",
    "                device_results[exp][model_type] = metric_function(infidelities['infidelities'].reshape((-1,))/100, predictions.reshape((-1,))/100)\n",
    "    return device_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diffs(results: dict, model1: str, model2: str) -> dict:\n",
    "    '''\n",
    "    Loop over the entries in results and compute the difference between model1's entries and model2's entries.\n",
    "    '''\n",
    "    diff_dict = {exp: result[model1] - result[model2] for exp, result in results.items()}\n",
    "    return diff_dict\n",
    "\n",
    "def compute_relative_diffs(results: dict, model1: str, model2: str) -> dict:\n",
    "    '''\n",
    "    Loop over the entries in results and compute the difference between model1's entries and model2's entries.\n",
    "    '''\n",
    "    diff_dict = {exp: 100*(result[model1] - result[model2]) / result[model2] for exp, result in results.items()}\n",
    "    return diff_dict\n",
    "\n",
    "def compute_statistic(results: dict, models: list, statistic: np.mean, s_kwargs = {}) -> dict: \n",
    "    '''\n",
    "    Loop over the devices in results and compute the (statistic) value of a metric for a model type.\n",
    "    '''\n",
    "    r_dict = {model: [] for model in models}\n",
    "    mean_dict = {model: None for model in models}\n",
    "    for _, result in results.items():\n",
    "        for model in models:\n",
    "            r_dict[model].append(result[model])\n",
    "    for model, item in r_dict.items():\n",
    "        mean_dict[model] = statistic(item, **s_kwargs)\n",
    "    return mean_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing on random circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: {'custom-nn': 0.17595568810144338, 'cnn': 0.40362890227131787},\n",
       "  1: {'custom-nn': 0.19929601750709453, 'cnn': 0.4211730323686552},\n",
       "  2: {'custom-nn': 0.19045894900771967, 'cnn': 0.4057395560832049},\n",
       "  3: {'custom-nn': 0.19063093026996736, 'cnn': 0.36667339892587436},\n",
       "  4: {'custom-nn': 0.19460001716886038, 'cnn': 0.4052834963861194}},\n",
       " {'custom-nn': 0.19018832041101708, 'cnn': 0.4004996772070344},\n",
       " {'custom-nn': 0.00873570518706385, 'cnn': 0.02019738858164003})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_types = ['custom-nn', 'cnn']\n",
    "circuits = 'test'\n",
    "\n",
    "m1, m2 = model_types\n",
    "metrics = ['l1']\n",
    "for metric in metrics:\n",
    "    results = aggregate_data(metric_functions[metric], model_types, circuits)\n",
    "\n",
    "m_dict = compute_statistic(results, [m1, m2], np.mean)\n",
    "std_dict = compute_statistic(results, [m1, m2], np.std, {'ddof': 1})\n",
    "results, m_dict, std_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-52.42820735008214, 3.0000116097852123)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_diff_dict = compute_relative_diffs(results, m1, m2)\n",
    "mean_percent_diff = np.mean([item for _, item in percent_diff_dict.items()])\n",
    "std_percent_diff = np.std([item for _, item in percent_diff_dict.items()], ddof = 1)\n",
    "mean_percent_diff, std_percent_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing on mirror circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: {'mirrored-custom-nn': 0.7198123508255867,\n",
       "   'mirrored-cnn': 1.1739220349082637},\n",
       "  1: {'mirrored-custom-nn': 0.6521377312879126,\n",
       "   'mirrored-cnn': 0.9220692764762998},\n",
       "  2: {'mirrored-custom-nn': 0.7691960288610059,\n",
       "   'mirrored-cnn': 1.2005252504890307},\n",
       "  3: {'mirrored-custom-nn': 0.7194130564263412,\n",
       "   'mirrored-cnn': 1.017424755623406},\n",
       "  4: {'mirrored-custom-nn': 0.7612372097169209,\n",
       "   'mirrored-cnn': 1.0458284406857643}},\n",
       " {'mirrored-custom-nn': 0.7243592754235534,\n",
       "  'mirrored-cnn': 1.0719539516365528},\n",
       " {'mirrored-custom-nn': 0.04645268436689402,\n",
       "  'mirrored-cnn': 0.11516234224226066})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_types = ['mirrored-custom-nn', 'mirrored-cnn']\n",
    "circuits = 'mirrored'\n",
    "\n",
    "metrics = ['l1']\n",
    "for metric in metrics:\n",
    "    results = aggregate_data(metric_functions[metric], model_types, circuits)\n",
    "\n",
    "m1, m2 = model_types\n",
    "\n",
    "m_dict = compute_statistic(results, [m1, m2], np.mean)\n",
    "std_dict = compute_statistic(results, [m1, m2], np.std, {'ddof': 1})\n",
    "results, m_dict, std_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-32.077772103462245, 4.943646369244539)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_diff_dict = compute_relative_diffs(results, m1, m2)\n",
    "mean_percent_diff = np.mean([item for _, item in percent_diff_dict.items()])\n",
    "std_percent_diff = np.std([item for _, item in percent_diff_dict.items()], ddof = 1)\n",
    "mean_percent_diff, std_percent_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# r value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom networks - random circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9684392681217231,\n",
       "  0.9596715887004044,\n",
       "  0.9702071654644208,\n",
       "  0.9522838751667093,\n",
       "  0.9599974257322668],\n",
       " 0.9621198646371049,\n",
       " 0.007290143789762289)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps = [0, 1, 2, 3, 4]\n",
    "ground = 'processed_infidelities.npz'\n",
    "preds = 'processed_custom_neural_net_predictions.npz'\n",
    "metric = 'r'\n",
    "\n",
    "predictions = [np.load(pred_path.format(exp) + preds)['test'].reshape((-1,)) for exp in exps]\n",
    "infidelities = [np.load(sps_path.format(exp) + ground)['test'].reshape((-1,)) for exp in exps]\n",
    "\n",
    "metrics = [metric_functions[metric](p, i) for p,i in zip(predictions, infidelities)]\n",
    "metrics, np.mean(metrics), np.std(metrics, ddof = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs - random circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.7505361525027514,\n",
       "  0.740882245477375,\n",
       "  0.7316650834712786,\n",
       "  0.7642203792560764,\n",
       "  0.7625715799442024],\n",
       " 0.7499750881303366,\n",
       " 0.01248880119651289)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps = [0, 1, 2, 3, 4]\n",
    "ground = 'processed_infidelities.npz'\n",
    "preds = 'processed_cnn_predictions.npz'\n",
    "metric = 'r'\n",
    "\n",
    "predictions = [np.load(pred_path.format(exp) + preds)['test'].reshape((-1,)) for exp in exps]\n",
    "infidelities = [np.load(sps_path.format(exp) + ground)['test'].reshape((-1,)) for exp in exps]\n",
    "\n",
    "metrics = [metric_functions[metric](p, i) for p,i in zip(predictions, infidelities)]\n",
    "metrics, np.mean(metrics), np.std(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom networks - mirrored circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9138791847764333,\n",
       "  0.9211639497171052,\n",
       "  0.9140251587778714,\n",
       "  0.911793000949433,\n",
       "  0.8979189324065388],\n",
       " 0.9117560453254763,\n",
       " 0.008509293767400028)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps = [0, 1, 2, 3, 4]\n",
    "ground = 'processed_mirrored_infidelities.npz'\n",
    "preds = 'processed_custom_neural_net_mirrored_predictions.npz'\n",
    "metric = 'r'\n",
    "\n",
    "predictions = [np.load(pred_path.format(exp) + preds)['predictions'] for exp in exps]\n",
    "infidelities = [np.load(sps_path.format(exp) + ground)['infidelities'] for exp in exps]\n",
    "\n",
    "metrics = [metric_functions[metric](p, i) for p,i in zip(predictions, infidelities)]\n",
    "metrics, np.mean(metrics), np.std(metrics, ddof = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs - mirrored circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8723350834502468,\n",
       "  0.8606129905299384,\n",
       "  0.8530316724664053,\n",
       "  0.8569320381621299,\n",
       "  0.8472077415570233],\n",
       " 0.8580239052331488,\n",
       " 0.008421604870836109)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps = [0, 1, 2, 3, 4]\n",
    "ground = 'processed_mirrored_infidelities.npz'\n",
    "preds = 'processed_cnn_mirrored_predictions.npz'\n",
    "metric = 'r'\n",
    "\n",
    "predictions = [np.load(pred_path.format(exp) + preds)['predictions'] for exp in exps]\n",
    "infidelities = [np.load(sps_path.format(exp) + ground)['infidelities'] for exp in exps]\n",
    "\n",
    "metrics = [metric_functions[metric](p, i) for p,i in zip(predictions, infidelities)]\n",
    "metrics, np.mean(metrics), np.std(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuit statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random circuit depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [0, 1, 2, 3, 4]\n",
    "exp_path = './experiment_{}/'\n",
    "df_path = exp_path + '/simulation_results/high-fidelity-dataframe.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(metric: str) -> dict:\n",
    "    results = {}\n",
    "    for exp in exps:\n",
    "        df = pd.read_csv(df_path.format(exp))\n",
    "        min_metric, max_metric = min(df[metric]), max(df[metric])\n",
    "        results[exp] = {'min': min_metric, 'max': max_metric}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'min': 1, 'max': 180},\n",
       " 1: {'min': 1, 'max': 180},\n",
       " 2: {'min': 1, 'max': 180},\n",
       " 3: {'min': 1, 'max': 180},\n",
       " 4: {'min': 1, 'max': 180}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_results = aggregate_data('F:Depth')\n",
    "depth_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mirror circuit depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [0, 1, 2, 3, 4]\n",
    "exp_path = './experiment_{}/'\n",
    "df_path = exp_path + '/simulation_results/mirrored_dataframe.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'min': 8, 'max': 174},\n",
       " 1: {'min': 7, 'max': 174},\n",
       " 2: {'min': 9, 'max': 172},\n",
       " 3: {'min': 7, 'max': 170},\n",
       " 4: {'min': 7, 'max': 172}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_depth_results = aggregate_data('F:Depth')\n",
    "m_depth_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MeanSquaredError\n",
    "\n",
    "import json\n",
    "\n",
    "from pygsti.extras import ml\n",
    "\n",
    "exp_num = 1\n",
    "\n",
    "model_path = f'./experiment_{exp_num}/models/'\n",
    "exp_path = f'./experiment_{exp_num}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 18s 18s/step\n",
      "Model: \"circuit_error_vec_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [None]                    0         \n",
      "                                                                 \n",
      " localized_dense_to_err_vec_  multiple                 299772    \n",
      " 2 (LocalizedDenseToErrVec)                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 299,772\n",
      "Trainable params: 299,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with open(exp_path + '/meta.json', 'r') as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "num_qubits = meta['num_qubits']\n",
    "max_error_weight = meta['max_error_weight']\n",
    "num_channels = meta['num_channels']\n",
    "num_hops = meta['num_hops']\n",
    "geometry = meta['geometry']\n",
    "\n",
    "if meta['geometry'] == 'ring':\n",
    "    adj_matrix = ml.newtools.ring_adj_matrix(num_qubits)\n",
    "elif meta['geometry'] == 'algiers-t-bar':\n",
    "    adj_matrix = ml.newtools.algiers_t_bar_adj_matrix()\n",
    "elif meta['geometry'] == 't-bar':\n",
    "    adj_matrix = ml.newtools.t_bar_adj_matrix()\n",
    "elif meta['geometry'] == 'bowtie':\n",
    "    adj_matrix = ml.newtools.bowtie_adj_matrix()\n",
    "elif meta['geometry'] == 'melbourne':\n",
    "    adj_matrix = ml.newtools.melbourne_adj_matrix()\n",
    "else:\n",
    "    print(f'You have not implemented the {geometry} geometry.')\n",
    "\n",
    "laplace = ml.newtools.laplace_from_qubit_graph(adj_matrix)\n",
    "\n",
    "error_gens = ml.newtools.up_to_weight_k_error_gens_from_qubit_graph(max_error_weight, num_qubits, laplace, num_hops)\n",
    "error_gen_indices = [ml.newtools.error_gen_to_index(error[0], error[1]) for error in error_gens]\n",
    "\n",
    "\n",
    "layer_snipper = ml.newneuralnets.layer_snipper_from_qubit_graph\n",
    "layer_snipper_args = [num_qubits, num_channels, laplace, num_hops]\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "\n",
    "circuits = np.load(exp_path+'/processed_inputs_and_outputs/processed_high_fidelity_circuits.npz')\n",
    "infidelities = np.load(exp_path+'/processed_inputs_and_outputs/processed_infidelities.npz')\n",
    "\n",
    "circuit_dense1 = ml.newneuralnets.CircuitErrorVec(num_qubits, num_channels, error_gens, layer_snipper,\n",
    "                                                layer_snipper_args)\n",
    "\n",
    "circuit_dense1.predict(circuits['train'][0:1])\n",
    "\n",
    "circuit_dense1.summary()\n",
    "\n",
    "# circuit_dense.load_weights(model_path.format(device) + 'custom_neural_network')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
